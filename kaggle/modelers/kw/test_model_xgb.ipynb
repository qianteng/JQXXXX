{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, scipy as sp, pandas as pd, sklearn as skl, matplotlib.pyplot as plt \n",
    "import xgboost as xgb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data \n",
    "train_orig = pd.read_csv('data/train.csv')\n",
    "test_orig = pd.read_csv('data/test.csv')\n",
    "subm_orig = pd.read_csv('data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#ttypes = [int(x.split('_')[1]) for x in subm_orig.columns[1:]]\n",
    "#int2ttype = dict([(i,x) for  i,x in enumerate(ttypes)])\n",
    "#ttype2int = dict([(x,i) for  i,x in enumerate(ttypes)])\n",
    "lencTT=skl.preprocessing.LabelEncoder()\n",
    "lencTT.fit(train_orig.TripType.reshape(-1,1))\n",
    "\n",
    "# do not use label encoder for weekdays, retain order \n",
    "d2int = {}\n",
    "d2int['Monday'] = 2\n",
    "d2int['Tuesday'] = 3\n",
    "d2int['Wednesday'] = 4\n",
    "d2int['Thursday'] = 5\n",
    "d2int['Friday'] = 6\n",
    "d2int['Saturday'] = 0\n",
    "d2int['Sunday'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feature desc\n",
    "#DD: can be nan, need to fill \n",
    "# scan count, can be negative (-12,71)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:147: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TripType                   int64\n",
      "VisitNumber                int32\n",
      "Weekday                   object\n",
      "Upc                      float64\n",
      "ScanCount                  int64\n",
      "DepartmentDescription     object\n",
      "FinelineNumber             int64\n",
      "TTint                      int64\n",
      "Wdint                      int64\n",
      "fldd                      object\n",
      "DDint                      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "train=train_orig.copy()\n",
    "\n",
    "lencDD = skl.preprocessing.LabelEncoder()\n",
    "lencDD.fit(np.unique(train['DepartmentDescription'].fillna('N/A')))\n",
    "\n",
    "def OHEncCol(df, col): # col must be numerical value \n",
    "    enc=skl.preprocessing.OneHotEncoder()\n",
    "    enc.fit(df[col].reshape(-1,1))\n",
    "    newCols = [col + '_' + str(x) for x in enc.active_features_]\n",
    "    df=pd.concat([df, pd.DataFrame(columns=newCols)])\n",
    "    df[newCols] = enc.transform(df[col].reshape(-1,1)).toarray()\n",
    "    return df \n",
    "\n",
    "def preprocess(df, lencDD = lencDD):\n",
    "    df['VisitNumber'] = df['VisitNumber'].astype(np.int32)\n",
    "    if 'TripType' in df.columns:\n",
    "        df['TTint']=lencTT.transform(df.TripType.reshape(-1,1)) # only do this w /training sample \n",
    "    df['Wdint']=df.Weekday.replace(d2int)\n",
    "    df['FinelineNumber']=df.FinelineNumber.fillna(-1).astype(int)\n",
    "    df['DepartmentDescription'] = df['DepartmentDescription'].fillna('N/A')\n",
    "    df['fldd'] = df['FinelineNumber'].apply(lambda x:str(int(x)))+ '_' +df['DepartmentDescription'].astype(str)\n",
    "    df['DDint'] = lencDD.transform(df['DepartmentDescription'])\n",
    "    # OH encode weekdays \n",
    "    \n",
    "    print (df.dtypes)\n",
    "    return df\n",
    "\n",
    "\n",
    "train = preprocess(train)\n",
    "#train=OHEncCol(train, 'Wdint')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95674 24645\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    #train[['VisitNumber','Wdint','Upc','ScanCount','DepartmentDescription','FinelineNumber']]\n",
    "#    train[features]\n",
    "#    ,train[['TTint']],test_size=0.3, random_state=10)\n",
    "\n",
    "# X_train\n",
    "\n",
    "# splitting using train_test_split doesn't work, need to split by visit number\n",
    "uniqv = np.unique(train.VisitNumber) \n",
    "vn2 = set(np.random.choice(uniqv, int(len(uniqv)*0.3))) ; print len(uniqv), len(vn2)\n",
    "idx1 = [x not in vn2 for x in train.VisitNumber]\n",
    "idx2 = [x in vn2 for x in train.VisitNumber]\n",
    "train1 = train[idx1]\n",
    "train2 = train[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def multiclassLogLoss(y_true, y_pred, eps=1e-15):   # true is n x 1, pred is n x p, \n",
    "    predictions = np.clip(y_pred, eps, 1 - eps)\n",
    "    # normalize\n",
    "    predictions /= predictions.sum(axis=1)[:, np.newaxis]\n",
    "    ohenc = skl.preprocessing.OneHotEncoder().fit(np.arange(y_pred.shape[1]).reshape(-1,1))\n",
    "    actual = ohenc.transform(y_true).toarray() # convert y into matrix w/ OH enc \n",
    "    return -1.0 / predictions.shape[0] * np.sum(actual * np.log(predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382\n",
      "isPopular\n",
      "False    183604\n",
      "True     463450\n",
      "Name: fldd, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# EDA \n",
    "#(train.groupby(['FinelineNumber','DepartmentDescription'])['ScanCount'].agg(len)>10).sum()\n",
    "# discretize <-1, -1, 1, 2, 3, 4-5, > 5\n",
    "#train.groupby('VisitNumber')['TripType'].agg(lambda x:len(np.unique(x))) # can predict by VN, instead of by line \n",
    "# plt.hist(np.minimum(30, train.groupby('VisitNumber')['Upc'].agg(len).values))  # distri of items purchased \n",
    "df = train.copy()\n",
    "minObs = 100  #  minObs 100 -> 1300 fldd, 500->200, 1000-> 69. , \n",
    "print (df.groupby(['fldd'])['ScanCount'].agg(len)>=minObs).sum()\n",
    "foo = df.groupby('fldd')['fldd'].agg(len)\n",
    "popularFldd = (foo[foo>minObs].index.values)\n",
    "\n",
    "lenc_fldd = skl.preprocessing.LabelEncoder()\n",
    "lenc_fldd.fit(np.array(list(popularFldd)) ) # .reshape(-1,1))\n",
    "\n",
    "df['isPopular'] = df.groupby('fldd').apply(lambda x: pd.Series([len(x)>=minObs] * len(x), index=x.index)).values\n",
    "print df.groupby('isPopular')['fldd'].agg(len)  # covers >80% of total obs \n",
    "#foo[foo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n"
     ]
    }
   ],
   "source": [
    "# feature space, Wdint (7) + sum(scancount of fldd)\n",
    "\n",
    "#df = train.copy() \n",
    "def makeSparseMat(df) : \n",
    "    dfVN = df[['VisitNumber','TripType','TTint','Wdint']].groupby(  # + ['Wdint_' + str(x) for x in xrange(7)]].groupby(\n",
    "        'VisitNumber').agg(lambda x:x.iloc[0])  # takes one minute, don't run every time \n",
    "    # dfVN =OHEncCol(dfVN, 'Wdint') #  no need to do OHE here, moved to sparse \n",
    "\n",
    "    dfVN['VisitNumber'] = dfVN.index \n",
    "    M, N = len(dfVN)  , len(popularFldd) + 7 # + weekdays \n",
    "\n",
    "    lenc_pfldd = skl.preprocessing.LabelEncoder()\n",
    "    lenc_pfldd.fit(popularFldd)\n",
    "    lencClsSet = set(lenc_pfldd.classes_)\n",
    "\n",
    "    scByVF = df.groupby(['VisitNumber','fldd'])['ScanCount'].agg(np.sum).reset_index()  # group by vn, fldd, and sum scancount \n",
    "    vnRowMap = pd.Series(np.arange(len(dfVN)), index=dfVN.index) # map from visit number to row index \n",
    "    csrDat = [0] * len(scByVF) * 2 \n",
    "    csrRowi = [0] * len(scByVF) * 2 \n",
    "    csrColi = [0] * len(scByVF) * 2  # times 2 to combine w/ weekday sparse mat as well \n",
    "    for i, r in dfVN.iterrows(): \n",
    "        csrDat[M + i] = 1 # need to fill weekday info \n",
    "        csrRowi[M + i] = vnRowMap.loc[r['VisitNumber']]\n",
    "        csrColi[M + i] =r['Wdint']\n",
    "    for i, r in scByVF.iterrows():\n",
    "        if i%10000 == 0 : \n",
    "            print i\n",
    "        if r['fldd'] in lencClsSet:    \n",
    "            csrDat[i] = r['ScanCount']\n",
    "            csrRowi[i] = vnRowMap.loc[r['VisitNumber']]\n",
    "            csrColi[i] = lenc_pfldd.transform(np.array([r['fldd']]))\n",
    "\n",
    "    sparMat = sp.sparse.csr_matrix((csrDat, (csrRowi, csrColi)), shape=(M,N))\n",
    "    return sparMat , dfVN['TTint'].values.reshape(-1,1)\n",
    "\n",
    "sp1, lb1 = makeSparseMat(train1) \n",
    "sp2, lb2 = makeSparseMat(train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95674 (95674, 76)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((71029, 1381), (24645, 1381))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print len(vnRowMap), sparMat.shape\n",
    "sparMat.toarray()[:30, :15]\n",
    "sp1.shape, sp2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n"
     ]
    }
   ],
   "source": [
    "# feature space, Wdint (7) + sum(scancount of fldd)\n",
    "\n",
    "df = train.copy() \n",
    "dfVN = df[['VisitNumber','TripType','TTint','Wdint']].groupby(  # + ['Wdint_' + str(x) for x in xrange(7)]].groupby(\n",
    "    'VisitNumber').agg(lambda x:x.iloc[0])  # takes one minute, don't run every time \n",
    "dfVN =OHEncCol(dfVN, 'Wdint')\n",
    "\n",
    "# takes a long time to run  \n",
    "\n",
    "for f in popularFldd:\n",
    "    dfVN[f] = 0\n",
    "\n",
    "#mat = np.zeros((len(dfVN), len(popularFldd)))\n",
    "for i, r in df.iterrows():#len(df)):\n",
    "    if i%10000 == 0 : \n",
    "        print i\n",
    "    if r['fldd'] in popularFldd:\n",
    "        dfVN.loc[r['VisitNumber'], r['fldd']] += r['ScanCount']\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['Wdint_' + str(x) for x in xrange(7)] + list(popularFldd)\n",
    "sub1 = [x not in vn2 for x in dfVN.index]\n",
    "sub2 = [x in vn2 for x in dfVN.index]\n",
    "dmtrain1 = xgb.DMatrix(dfVN.loc[sub1, features], label = dfVN.loc[sub1,'TTint'].tolist())\n",
    "dmtrain2 = xgb.DMatrix(dfVN.loc[sub2, features], label = dfVN.loc[sub2,'TTint'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sparse version \n",
    "features = ['Wdint_' + str(x) for x in xrange(7)] + list(popularFldd)\n",
    "dmtrain1 = xgb.DMatrix(sp1, label=lb1)\n",
    "dmtrain2 = xgb.DMatrix(sp2, label=lb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dmtrain1.save_binary('dmt1.buffer')\n",
    "#dmtrain2.save_binary('dmt2.buffer')\n",
    "#dmtrain1 = xgb.DMatrix('dmt1.buffer')\n",
    "#dmtrain2 = xgb.DMatrix('dmt2.buffer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit \n",
    "xgb_params = {'max_depth': 10,\n",
    "          'objective': 'multi:softprob',\n",
    "          'eval_metric': 'mlogloss',\n",
    "          'num_class': 38,\n",
    "          'subsample': 0.35,\n",
    "          'colsample_bytree': 1,\n",
    "          'eta': 0.7}\n",
    "\n",
    "watchlist = [(dmtrain1, 'train'), (dmtrain2, 'eval')]\n",
    "mod = xgb.train(xgb_params, dmtrain1, evals = watchlist,  verbose_eval=False, early_stopping_rounds=25)\n",
    "# mod.fit(X_train, y_train, eval_metric='mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1618854733313904"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = mod.predict(dmtrain2)\n",
    "multiclassLogLoss(dfVN.loc[sub2, ['TTint']].values, pred)   # 70 ftr, 2.8, 1300 ftr -> 2.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.509177072613519, 2.9781298680871839)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing non popular prediction vs modeled \n",
    "hasData = dfVN.loc[sub2, features].values[:,7:].sum(1) > 0\n",
    "multiclassLogLoss(dfVN.loc[sub2, ['TTint']][hasData].values, pred[hasData]), multiclassLogLoss(dfVN.loc[sub2, ['TTint']][np.logical_not(hasData)].values, pred[np.logical_not(hasData)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisitNumber                int32\n",
      "Weekday                   object\n",
      "Upc                      float64\n",
      "ScanCount                  int64\n",
      "DepartmentDescription     object\n",
      "FinelineNumber             int64\n",
      "Wdint                      int64\n",
      "fldd                      object\n",
      "DDint                      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "dfTest = test_orig.copy()\n",
    "dfTest = preprocess(dfTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n"
     ]
    }
   ],
   "source": [
    "def aggByTrip(df, popularFldd):\n",
    "\n",
    "    dfVN = df[[x for x in ['VisitNumber','TripType','TTint','Wdint'] if x in df.columns]].groupby( \n",
    "        'VisitNumber').agg(lambda x:x.iloc[0])  # takes one minute, don't run every time \n",
    "    dfVN =OHEncCol(dfVN, 'Wdint')\n",
    "\n",
    "    for f in popularFldd:\n",
    "        dfVN[f] = 0\n",
    "\n",
    "    for i, r in df.iterrows():#len(df)):\n",
    "        if i%10000 == 0 : \n",
    "            print i\n",
    "        if r['fldd'] in popularFldd:\n",
    "            dfVN.loc[r['VisitNumber'], r['fldd']] += r['ScanCount']\n",
    "        else:\n",
    "            continue\n",
    "    return dfVN \n",
    "\n",
    "dftVN = aggByTrip(dfTest, popularFldd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subMat =  np.concatenate((dftVN.index.values.reshape(-1,1), mod.predict(xgb.DMatrix(dftVN[features]))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('sub.csv'\n",
    "    , subMat\n",
    "    , fmt='%.5f', delimiter = ','\n",
    "    , header = ','.join(['VisitNumber'] + ['TripType_' + str(lencTT.inverse_transform(i)) for i in xrange(38)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lencTT.inverse_transform(37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
